{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb86f2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alta/Conversational/OET/al826/2022/shortcuts/shortcutlearningNLP/framework\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c50935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.system_loader import SystemLoader\n",
    "from src.utils.evaluation import get_accuracy\n",
    "\n",
    "system = SystemLoader('trained_models/single_seed/imdb/bert_shuf')\n",
    "system.set_up_helpers()\n",
    "system.data_loader.formatting = 'shuffle_stopwords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f68be9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/alta/Conversational/OET/al826/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0037123d3ff4a50b4f9c0873909f0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                         | 144/20000 [00:00<00:13, 1438.76it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|████████████████████████████████████████████████████████| 20000/20000 [00:13<00:00, 1484.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████| 5000/5000 [00:03<00:00, 1482.25it/s]\n",
      "100%|████████████████████████████████████████████████████████| 25000/25000 [00:16<00:00, 1512.08it/s]\n",
      "Reusing dataset imdb (/home/alta/Conversational/OET/al826/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313ef907db214b6587ddaf75a6ce459e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romantic comedy is not the correct way to describe \"How to lose friends & alienate people\". The underlying romance in the plot is, for the most part, displaced by a far more interesting \"rags to riches\" tale. Although the central line of the story is somewhat rushed passed, in several screen shots, it does have a sense of; getting the \"nitty gritty\" out of the way, focusing on those key relationships which make \"office politics\" and using those almost irrelevant scenes, used purely for comic effect. Yet it works so well, especially with Pegg in the front seat. The film is ultimately very clever, playing well on the trans-Atlantic relationship Pegg shares with his co-stars and merging the cross between the high and low -life society quite well and quite refreshingly in a storyline that despite predictability is somewhat of a unique journey. The different characters in the film are presented well and casting is definitely a plus point on the film. Both the \"trading places\" relationship between Pegg and Huston and the \"love, hate\" relationship between Pegg and Dunst do work so well in a story that is, for want of a better word, charming. Even Fox, whose main asset is of course sex appeal, shocks with what turns out to be quite a dark character and acts that \"bimbo\" role all to well. Its one of these films where every little detail does pay tribute to a great piece of work. From transsexual strippers to an amazing soundtrack it all meshes nicely into what can only be described as clever comedy.\n",
      "[CLS] is not the to how to the in the is for the most by a more to the of the is in it does have a of the out of the on those which and those for it so with in the the is very on the with his and the between the and and in a that is of a the in the are and is a on the both the between and and the between and do so in a that is for of a is of with what out to be a and that all to its of these where does to a of from to an it all into what can only be as [SEP]\n"
     ]
    }
   ],
   "source": [
    "system.data_loader.formatting = 'remove_content'\n",
    "\n",
    "batches = system._get_eval_batches('imdb', mode='dev')\n",
    "text_inputs = system.load_inputs('imdb', mode='dev')\n",
    "\n",
    "#batches = system._get_eval_batches('rt', mode='test')\n",
    "\n",
    "x = next(batches)\n",
    "text = text_inputs[0]\n",
    "\n",
    "print(text)\n",
    "print(system.data_loader.tokenizer.decode(x.ids[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bf03a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.data_loader.stop_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add03b58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdasd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43masdasd\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asdasd' is not defined"
     ]
    }
   ],
   "source": [
    "asdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa347869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def turn_probs_preds(probs):\n",
    "    preds = {}\n",
    "    for k, prob in probs.items():\n",
    "        preds[k] = int(np.argmax(prob, axis=-1))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d14eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = system._probs(data_name='twitter', mode='test')\n",
    "labels = system.load_labels('twitter',     mode='test')\n",
    "preds = turn_probs_preds(probs)\n",
    "print(get_accuracy(preds, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = system._probs(data_name='imdb', mode='dev')\n",
    "labels = system.load_labels('imdb',     mode='dev')\n",
    "preds = turn_probs_preds(probs)\n",
    "print(get_accuracy(preds, labels))\n",
    "\n",
    "probs = system._probs(data_name='rt', mode='test')\n",
    "labels = system.load_labels('rt',     mode='test')\n",
    "preds = turn_probs_preds(probs)\n",
    "print(get_accuracy(preds, labels))\n",
    "\n",
    "probs = system._probs(data_name='sst', mode='test')\n",
    "labels = system.load_labels('sst',     mode='test')\n",
    "preds = turn_probs_preds(probs)\n",
    "print(get_accuracy(preds, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
